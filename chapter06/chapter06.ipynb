{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP60/100_forsubmit",
      "provenance": [],
      "collapsed_sections": [
        "u8gDrl6YHpZP",
        "d87lKthmioJi",
        "NxreDPbWGYVh",
        "oiU08ynGs27m"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_PkjDeDt2Hs"
      },
      "source": [
        "# 6章 機械学習  \n",
        "本章では，Fabio Gasparetti氏が公開しているNews Aggregator Data Setを用い，ニュース記事の見出しを「ビジネス」「科学技術」「エンターテイメント」「健康」のカテゴリに分類するタスク（カテゴリ分類）に取り組む．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xV-h7VC0uA2o"
      },
      "source": [
        "## 50. データの入手・整形\n",
        ">[News Aggregator Data Set](https://archive.ics.uci.edu/ml/datasets/News+Aggregator)をダウンロードし、以下の要領で学習データ（train.txt），検証データ（valid.txt），評価データ（test.txt）を作成せよ．  \n",
        " 1. ダウンロードしたzipファイルを解凍し，readme.txtの説明を読む．\n",
        " 2. 情報源（publisher）が”Reuters”, “Huffington Post”, “Businessweek”, “Contactmusic.com”, “Daily Mail”の事例（記事）のみを抽出する．\n",
        " 3. 抽出された事例をランダムに並び替える．\n",
        " 4. 抽出された事例の80%を学習データ，残りの10%ずつを検証データと評価データに分割し，それぞれtrain.txt，valid.txt，test.txtというファイル名で保存する．ファイルには，１行に１事例を書き出すこととし，カテゴリ名と記事見出しのタブ区切り形式とせよ（このファイルは後に問題70で再利用する）．  \n",
        " >\n",
        ">学習データと評価データを作成したら，各カテゴリの事例数を確認せよ．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "372AnX16o77P"
      },
      "source": [
        "# 指定のデータをダウンロード\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00359/NewsAggregatorDataset.zip\n",
        "!unzip NewsAggregatorDataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-_XWqkxpNsK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1fb751a-fe91-4d7d-c1f3-14802cf13eec"
      },
      "source": [
        "# 確認\n",
        "!head -10 ./newsCorpora.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\tFed official says weak data caused by weather, should not slow taper\thttp://www.latimes.com/business/money/la-fi-mo-federal-reserve-plosser-stimulus-economy-20140310,0,1312750.story\\?track=rss\tLos Angeles Times\tb\tddUyU0VZz0BRneMioxUPQVP6sIxvM\twww.latimes.com\t1394470370698\n",
            "2\tFed's Charles Plosser sees high bar for change in pace of tapering\thttp://www.livemint.com/Politics/H2EvwJSK2VE6OF7iK1g3PP/Feds-Charles-Plosser-sees-high-bar-for-change-in-pace-of-ta.html\tLivemint\tb\tddUyU0VZz0BRneMioxUPQVP6sIxvM\twww.livemint.com\t1394470371207\n",
            "3\tUS open: Stocks fall after Fed official hints at accelerated tapering\thttp://www.ifamagazine.com/news/us-open-stocks-fall-after-fed-official-hints-at-accelerated-tapering-294436\tIFA Magazine\tb\tddUyU0VZz0BRneMioxUPQVP6sIxvM\twww.ifamagazine.com\t1394470371550\n",
            "4\tFed risks falling 'behind the curve', Charles Plosser says\thttp://www.ifamagazine.com/news/fed-risks-falling-behind-the-curve-charles-plosser-says-294430\tIFA Magazine\tb\tddUyU0VZz0BRneMioxUPQVP6sIxvM\twww.ifamagazine.com\t1394470371793\n",
            "5\tFed's Plosser: Nasty Weather Has Curbed Job Growth\thttp://www.moneynews.com/Economy/federal-reserve-charles-plosser-weather-job-growth/2014/03/10/id/557011\tMoneynews\tb\tddUyU0VZz0BRneMioxUPQVP6sIxvM\twww.moneynews.com\t1394470372027\n",
            "6\tPlosser: Fed May Have to Accelerate Tapering Pace\thttp://www.nasdaq.com/article/plosser-fed-may-have-to-accelerate-tapering-pace-20140310-00371\tNASDAQ\tb\tddUyU0VZz0BRneMioxUPQVP6sIxvM\twww.nasdaq.com\t1394470372212\n",
            "7\tFed's Plosser: Taper pace may be too slow\thttp://www.marketwatch.com/story/feds-plosser-taper-pace-may-be-too-slow-2014-03-10\\?reflink=MW_news_stmp\tMarketWatch\tb\tddUyU0VZz0BRneMioxUPQVP6sIxvM\twww.marketwatch.com\t1394470372405\n",
            "8\tFed's Plosser expects US unemployment to fall to 6.2% by the end of 2014\thttp://www.fxstreet.com/news/forex-news/article.aspx\\?storyid=23285020-b1b5-47ed-a8c4-96124bb91a39\tFXstreet.com\tb\tddUyU0VZz0BRneMioxUPQVP6sIxvM\twww.fxstreet.com\t1394470372615\n",
            "9\tUS jobs growth last month hit by weather:Fed President Charles Plosser\thttp://economictimes.indiatimes.com/news/international/business/us-jobs-growth-last-month-hit-by-weatherfed-president-charles-plosser/articleshow/31788000.cms\tEconomic Times\tb\tddUyU0VZz0BRneMioxUPQVP6sIxvM\teconomictimes.indiatimes.com\t1394470372792\n",
            "10\tECB unlikely to end sterilisation of SMP purchases - traders\thttp://www.iii.co.uk/news-opinion/reuters/news/152615\tInteractive Investor\tb\tdPhGU51DcrolUIMxbRm0InaHGA2XM\twww.iii.co.uk\t1394470501265\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZmGrc4tqM2D"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# データの読込\n",
        "df = pd.read_csv('./newsCorpora.csv',sep='\\t', usecols=[1,3,4], names=['TITLE', 'PUBLISHER', 'CATEGORY'])\n",
        "\n",
        "# データの抽出\n",
        "df = df.loc[df['PUBLISHER'].isin(['Reuters', 'Huffington Post', 'Businessweek', 'Contactmusic.com', 'Daily Mail']), ['TITLE', 'CATEGORY']]\n",
        "# isisn()はbool型を返す\n",
        "# つまり、ある値がデータフレームやシリーズの中に存在すれば「True」を返し、その値が存在しなければ「False」を返す\n",
        "# loc[縦, 横]で任意の位置の値を取得。今回は特定のPUBLISHER(縦)のうちの、TITLEとCATEGORY(横)を取得。\n",
        "\n",
        "# データの分割\n",
        "train, valid_test = train_test_split(df, test_size=0.2, shuffle=True, random_state=123, stratify=df['CATEGORY'])\n",
        "valid, test = train_test_split(valid_test, test_size=0.5, shuffle=True, random_state=123, stratify=valid_test['CATEGORY'])\n",
        "# train_test_split()にNumPy配列ndarrayを渡すと、二分割されたndarrayが要素として格納されたリストが返される。\n",
        "# シャッフルされる場合、デフォルトでは実行するたびにランダムに分割される。引数random_stateを指定して乱数シードを固定すると常に同じように分割される。\n",
        "# 　機械学習のモデルの性能を比較するような場合、どのように分割されるかによって結果が異なってしまうため、乱数シードを固定して常に同じように分割されるようにする必要がある\n",
        "# 引数stratifyに均等に分割させたいデータ（多くの場合は正解ラベル）を指定すると、そのデータの値の比率が一致するように分割される。\n",
        "# 　これにより、訓練データに正解のデータしかないというような偏りをなくすことが出来る。"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8gDrl6YHpZP"
      },
      "source": [
        "## 51. 特徴量抽出\n",
        "\n",
        ">学習データ，検証データ，評価データから特徴量を抽出し，それぞれtrain.feature.txt，valid.feature.txt，test.feature.txtというファイル名で保存せよ． なお，カテゴリ分類に有用そうな特徴量は各自で自由に設計せよ．記事の見出しを単語列に変換したものが最低限のベースラインとなるであろう"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnQTXKP86AKf"
      },
      "source": [
        "記事の見出しの単語群からTF-IDFを算出"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54nLOvRF5Xv0"
      },
      "source": [
        "import string\n",
        "import re\n",
        "\n",
        "# 前処理\n",
        "def preprocessing(text):\n",
        "  # Plosser: → Plosser\n",
        "  table = str.maketrans(string.punctuation, ' '*len(string.punctuation))  # 文字列変換テーブルの作成  # sting.punctuation：記号\n",
        "   # maketrans(辞書)の形だと、１文字を任意の長さに変換できるが、maketrans(変換前, 変換後)だと１文字は１文字にしか変換できない \n",
        "  text = text.translate(table)  # 記号をスペースに置換\n",
        "  \n",
        "  text = text.lower()  # 小文字化\n",
        "  text = re.sub('[0-9]+', '0', text)  # 数字列を0に置換\n",
        "\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yu6wZfIb6geX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9455b671-6a4d-43bc-e1b0-37970856d1a8"
      },
      "source": [
        "# データの再結合\n",
        "df = pd.concat([train, valid, test], axis=0)\n",
        "df.reset_index(drop=True, inplace=True)  # indexを振りなおす\n",
        "# 引数dropをTrueとすると、元のindexは削除され残らない\n",
        "# デフォルトでは元のオブジェクトは変更されず、新たなオブジェクトが返されるが、引数inplaceをTrueとすると元のオブジェクトが変更される\n",
        "\n",
        "# 前処理の実施\n",
        "df['TITLE'] = df['TITLE'].map(lambda x: preprocessing(x))\n",
        "# map関数では、リストなどの各要素に対して何かしらの変換を加えて別のオブジェクトを生成させることができる\n",
        "# 第一引数に関数、第二引数にシーケンスを指定し、シーケンスの各要素に対して関数を適用する\n",
        "\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                               TITLE CATEGORY\n",
            "0  fitch lowers south africa credit rating outloo...        b\n",
            "1  forex dollar rises on us rate speculation afte...        b\n",
            "2  update 0 mexico s lower house generally approv...        b\n",
            "3  u s  navy seals take control of north korean f...        b\n",
            "4  beyonce   beyonce and jay z pay tribute to mic...        e\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-QdlnR82iGT"
      },
      "source": [
        "tf：Term Frequencyで，単語の出現頻度。文書dにおける単語wのtfは　wの出現数 / dの単語数 。「文書中により高頻度で出現する単語ほど，その文書にとって重要だ」という考え。  \n",
        "idf：Inverse Document Frequencyで，逆文書頻度。文書群における単語wのidfは　log(文書数 / wが入っている文書数)　。「特定の文書に出現する単語ほど，ある話題に特化した意味のある単語である」という考え。  \n",
        "tf-idf：上記２つの積"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvVXGOIH4AMw"
      },
      "source": [
        "# TfidfVectorizerは，文書群を与えると，各文書をtf-Idfの値を元にしたベクトルに変換するもの\n",
        "# 入力は文字列のリストです．1つの文字列が1つの文書に相当します\n",
        "# 出力は2次元の行列が返る。正確にはscipy(ｻｲﾊﾟｲ)のオブジェクトで，shapeは(文書数, 語彙サイズ)。各文書の存在する単語がTfidfに置き換わったリスト\n",
        "# fit()メソッドで、入力の文書群を与えて，語彙の獲得やidfの計算\n",
        "# transform()メソッドで、fit()したことで得た語彙やidfを元に，文書をtf-idf行列に変換。pythonのリストのように出力したい場合は，toarray()を使用\n",
        "# fit_transform()は、fit()とtransform()を同時に行います．\n",
        "# get_feature_names()は、特徴量ラベル（＝語彙）を表示します．transform()した後の行列では語彙サイズが列数になりますが，どの列がどの単語なのかを知る場合には，この関数を使います．\n",
        "\n",
        "# min_df(①0~1,②整数)\n",
        "  # 各単語において①使用されている文章の割合、または②使用されている文章数がパラメータ以下の単語を排除します。あまりにも使用されていない単語は排除するという考えです。"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdQirr4b6uOa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a90d9feb-8b04-4610-995c-27ac891d81b7"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer  # サイキットラーン\n",
        "\n",
        "# データの分割\n",
        "train_valid = df[:len(train) + len(valid)]\n",
        "test = df[len(train) + len(valid):]\n",
        "\n",
        "# TfidfVectorizer(インスタンス生成)\n",
        "vec_tfidf = TfidfVectorizer(min_df=10)  # ngram_rangeでTF-IDFを計算する単語の長さを指定\n",
        "                                                            # min_dfで特徴量の抽出数を制限。あまりに低い頻出度のものを除外？\n",
        "\n",
        "# ベクトル化\n",
        "X_train_valid = vec_tfidf.fit_transform(train_valid['TITLE'])  # testの情報は使わない(testデータ以外のデータから、語彙マップとidfを作成？(=学習))\n",
        "# testの語彙を抜いてtrainとvalidの語彙だけで語彙マップを作るために、testを切り離した？\n",
        "X_test = vec_tfidf.transform(test['TITLE'])  # テストデータで、モデルの語彙に基づくtf-idfを算出し、精度確認？(idfはモデルのを使用し、tfだけ新たに計算...？)\n",
        "\n",
        "# ベクトルをデータフレームに変換\n",
        "X_train_valid = pd.DataFrame(X_train_valid.toarray(), columns=vec_tfidf.get_feature_names())\n",
        "X_test = pd.DataFrame(X_test.toarray(), columns=vec_tfidf.get_feature_names())\n",
        "\n",
        "# データの分割\n",
        "X_train = X_train_valid[:len(train)]\n",
        "X_valid = X_train_valid[len(train):]\n",
        "\n",
        "\n",
        "print(display(X_train))  # 縦：記事数　横：語彙リストに対する各記事中のtf-idf値"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0d</th>\n",
              "      <th>0m</th>\n",
              "      <th>0nd</th>\n",
              "      <th>0s</th>\n",
              "      <th>0st</th>\n",
              "      <th>0th</th>\n",
              "      <th>aa</th>\n",
              "      <th>abbvie</th>\n",
              "      <th>abc</th>\n",
              "      <th>about</th>\n",
              "      <th>above</th>\n",
              "      <th>abramson</th>\n",
              "      <th>abs</th>\n",
              "      <th>abuse</th>\n",
              "      <th>accelerates</th>\n",
              "      <th>access</th>\n",
              "      <th>accident</th>\n",
              "      <th>accord</th>\n",
              "      <th>account</th>\n",
              "      <th>accused</th>\n",
              "      <th>ackman</th>\n",
              "      <th>acquire</th>\n",
              "      <th>across</th>\n",
              "      <th>act</th>\n",
              "      <th>acting</th>\n",
              "      <th>action</th>\n",
              "      <th>activists</th>\n",
              "      <th>actor</th>\n",
              "      <th>actress</th>\n",
              "      <th>actually</th>\n",
              "      <th>ad</th>\n",
              "      <th>adam</th>\n",
              "      <th>adds</th>\n",
              "      <th>admits</th>\n",
              "      <th>ads</th>\n",
              "      <th>advance</th>\n",
              "      <th>advances</th>\n",
              "      <th>advice</th>\n",
              "      <th>aereo</th>\n",
              "      <th>affirms</th>\n",
              "      <th>...</th>\n",
              "      <th>woes</th>\n",
              "      <th>woman</th>\n",
              "      <th>women</th>\n",
              "      <th>won</th>\n",
              "      <th>woodley</th>\n",
              "      <th>woody</th>\n",
              "      <th>words</th>\n",
              "      <th>work</th>\n",
              "      <th>worker</th>\n",
              "      <th>workers</th>\n",
              "      <th>working</th>\n",
              "      <th>works</th>\n",
              "      <th>world</th>\n",
              "      <th>worries</th>\n",
              "      <th>worst</th>\n",
              "      <th>worth</th>\n",
              "      <th>would</th>\n",
              "      <th>wrapup</th>\n",
              "      <th>wren</th>\n",
              "      <th>wrong</th>\n",
              "      <th>wsj</th>\n",
              "      <th>wti</th>\n",
              "      <th>xbox</th>\n",
              "      <th>yahoo</th>\n",
              "      <th>year</th>\n",
              "      <th>years</th>\n",
              "      <th>yellen</th>\n",
              "      <th>yen</th>\n",
              "      <th>yet</th>\n",
              "      <th>yield</th>\n",
              "      <th>yields</th>\n",
              "      <th>york</th>\n",
              "      <th>you</th>\n",
              "      <th>young</th>\n",
              "      <th>your</th>\n",
              "      <th>yr</th>\n",
              "      <th>yuan</th>\n",
              "      <th>zac</th>\n",
              "      <th>zendaya</th>\n",
              "      <th>zone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.34156</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10667</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10668</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10669</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.324928</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10670</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.388372</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10671</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.724192</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.246614</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10672 rows × 2131 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0d   0m  0nd   0s  0st  0th  ...  your   yr  yuan  zac  zendaya  zone\n",
              "0      0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0   0.0  0.0      0.0   0.0\n",
              "1      0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0   0.0  0.0      0.0   0.0\n",
              "2      0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0   0.0  0.0      0.0   0.0\n",
              "3      0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0   0.0  0.0      0.0   0.0\n",
              "4      0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0   0.0  0.0      0.0   0.0\n",
              "...    ...  ...  ...  ...  ...  ...  ...   ...  ...   ...  ...      ...   ...\n",
              "10667  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0   0.0  0.0      0.0   0.0\n",
              "10668  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0   0.0  0.0      0.0   0.0\n",
              "10669  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0   0.0  0.0      0.0   0.0\n",
              "10670  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0   0.0  0.0      0.0   0.0\n",
              "10671  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0   0.0  0.0      0.0   0.0\n",
              "\n",
              "[10672 rows x 2131 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d87lKthmioJi"
      },
      "source": [
        "## 52. 学習\n",
        "\n",
        ">51で構築した学習データを用いて，ロジスティック回帰モデルを学習せよ．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nr35JQigpmns"
      },
      "source": [
        "回帰分析 (Regression)は、ある目的変数Yの値を、パラメーターθによって重み付けされた説明変数Xによって予測する方法\n",
        "\n",
        "単回帰分析：1つの説明変数で1つの独立変数を求める  \n",
        "　　　　　　ex. 未知の説明変数(経験)からでも目的変数(給料)の数値を見積もる  \n",
        "重回帰分析：2つ以上の説明変数を用いて独立変数を求める  \n",
        "ロジスティック回帰：縦軸が定量データではなく、ゼロかイチを判定する二値分類の問題を解く場合に用いられる(多クラス分類もできる)  \n",
        "　　　　　　ex. ある商品のプロモーションにより購入されたか否か(Yes = 1 or No = 0)を年齢ごとに分類したデータから、新しいデータに対して商品を買う確率を計算する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sftj05Iom7WX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "272edd3c-fa92-4561-d392-7c02d393a065"
      },
      "source": [
        "# 目的変数が値なら重回帰分析で、カテゴリ(数値化できないもの)ならロジスティック回帰？\n",
        "# 今回は記事カテゴリ(bかhか...)を分類したいので、ロジスティック回帰\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# モデルの学習\n",
        "model = LogisticRegression(random_state=123, max_iter=10000)\n",
        "# random_state: 乱数生成器のシードを指定するパラメータ。数値（int型）かRandomStateインスタンスを指定する。モデルの再現性を担保するために、適当な値を指定しておいたほうがよい。\n",
        "\n",
        "\n",
        "model.fit(X_train, train['CATEGORY'])\n",
        "# fitメソッド：ロジスティック回帰モデルの重みを学習\n",
        "# 説明変数：各語彙　独立変数：カテゴリー(e, b, t, m)\n",
        "\n",
        "# 説明変数(語彙)の各値(特徴量)に重みをかける等で確率を導く。その重みを学習する。\n",
        "# Nクラス分類の時は、重み行列Wのサイズはc(説明変数の数)×N(クラスの数)。説明変数ベクトルを行ベクトルXとすると、各クラスの確率はXとWの行列積の各列の値となる"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxreDPbWGYVh"
      },
      "source": [
        "## 53. 予測\n",
        "\n",
        "52で学習したロジスティック回帰モデルを用い，与えられた記事見出しからカテゴリとその予測確率を計算するプログラムを実装せよ．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVA_7erxwbkZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af84d63b-7a8c-4bce-945f-6b68ae594d4f"
      },
      "source": [
        "import numpy as np\n",
        "# 最も高い確率の値とそのクラス名を返す\n",
        "train_pred = [model.predict(X_train), np.max(model.predict_proba(X_train), axis=1)]\n",
        "test_pred = [model.predict(X_test), np.max(model.predict_proba(X_test), axis=1)]\n",
        "                                    # ↑各行で一番大きい値を取得\n",
        "  # predict(X)：説明変数(入力X)の値からクラスラベルを予測\n",
        "  # predict_proba(X)：各クラスの確率を予測\n",
        "\n",
        "print(\"カテゴリ 確率\")\n",
        "for c, p in zip(train_pred[0][:5],train_pred[1][:5] ):\n",
        "  print(c, p)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "カテゴリ 確率\n",
            "b 0.9522361586123828\n",
            "b 0.9896971882323873\n",
            "b 0.6405835893803277\n",
            "b 0.5474147651494435\n",
            "e 0.986168611930441\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9H7mj0nVGk9O"
      },
      "source": [
        "## 54. 正解率の計測\n",
        "\n",
        "52で学習したロジスティック回帰モデルの正解率を，学習データおよび評価データ上で計測せよ．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBrHMDXpznop",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3658a2f-a74a-4fbe-a177-756eba81e281"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "# 正解率とは、分類したデータの総数のうち、正しく分類されたデータ数の割合\n",
        "train_acc = accuracy_score(train['CATEGORY'], train_pred[0])  # train_pred[0] : 確率が最も高いクラス名\n",
        "test_acc = accuracy_score(test['CATEGORY'], test_pred[0])\n",
        "print(f'学習データ：{train_acc:.3f}')\n",
        "print(f'評価データ：{test_acc:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "学習データ：0.920\n",
            "評価データ：0.884\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7z3MRbDXoyD"
      },
      "source": [
        "## 55. 混同行列の作成\n",
        "\n",
        "52で学習したロジスティック回帰モデルの混同行列（confusion matrix）を，学習データおよび評価データ上で作成せよ．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXN60sOdrhoT"
      },
      "source": [
        "　混同行列とは、実際のクラスが陰性(ex.病気じゃない),陽性(ex.病気である)のデータに対して、クラス陰,陽に分類されたデータの個数を要素とする行列です。\n",
        "出力結果の\n",
        "\n",
        "* 1行1列目の要素は、実際にクラス陰性で正しくクラス陰性に分類されたデータ数（真陰性（TN: True Negative））\n",
        "\n",
        "* 1行2列目の要素は、実際には陰性だが誤って陽性に分類されたデータ数（偽陽性（FP: False Positive））\n",
        "\n",
        "* 2行1列目の要素は、実際には陽性だが誤って陰性に分類されたデータ数（偽陰性（FN: False Negative））\n",
        "\n",
        "* 2行2列目の要素は、実際に陽性で正しく陽性に分類されたデータ数（真陽性（TP: True Positive））\n",
        "を表します。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRBe8MYMrOtc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "472a9fd6-fd66-4acd-9e0d-70828973189b"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# 学習データ\n",
        "train_cm = confusion_matrix(train['CATEGORY'], train_pred[0], labels=['b', 'e', 't', 'm'])  # 第一引数に実際のクラス（正解クラス）、第二引数に予測したクラスのリストや配列を指定する。\n",
        "print(train_cm)                                                                             # confusion_matrixの引数のlabelsに順番を指定すると、混同行列の列と行がその順番に並ぶ    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4326  106   64    6]\n",
            " [  63 4147   11    2]\n",
            " [ 192  154  865    8]\n",
            " [  98  133   14  483]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHX6KyDVzoL0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cd80fc5-63e4-45ff-ece0-f29eda40f55c"
      },
      "source": [
        "# 評価データ\n",
        "test_cm = confusion_matrix(test['CATEGORY'], test_pred[0])\n",
        "print(test_cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[529  23   2   9]\n",
            " [ 15 510   1   2]\n",
            " [ 13  33  40   5]\n",
            " [ 26  25   1 100]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wi8b2onXHtY"
      },
      "source": [
        "## 56. 適合率，再現率，F1スコアの計測\n",
        "\n",
        ">52で学習したロジスティック回帰モデルの適合率，再現率，F1スコアを，評価データ上で計測せよ．カテゴリごとに適合率，再現率，F1スコアを求め，カテゴリごとの性能をマイクロ平均（micro-average）とマクロ平均（macro-average）で統合せよ．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B93dUA0ixv5W"
      },
      "source": [
        "　真陽性・偽陰性・偽陽性・真陰性の「真・偽」は「分類が当たっているか」を表し、「陽性・陰性」は「クラス1・クラス0」を表します。たとえば、偽陰性は、予測されたクラスは陰性だが分類が間違っていることを表します。\n",
        "↓表で考えた方が分かりやすい\n",
        "\n",
        "* 正解率(Accuracy)とは、分類したデータの総数のうち、正しく分類されたデータ数の割合です。式で書くと、(TP+TN)/(TP+FN+FP+TN)です。  \n",
        "( 正しく認定 / 全体 )\n",
        "(正しく認定されたものの割合)\n",
        "\n",
        "* 適合率(Precision)とは、クラス1に分類されたデータのうち、実際にクラス1であるデータ数の割合です。式で書くと、TP/(TP+FP)です。正確性の指標。  \n",
        "( 実際の陽性で正しく認定 / 陽性認定)\n",
        "(陽性認定された中で正しく認定されたもの)\n",
        "\n",
        "* 再現率(Recall)とは、実際にクラス1であるデータのうち、クラス1に分類されたデータ数の割合です。式で書くと、TP/(TP+FN)です。網羅性の指標。\n",
        "( 陽性認定で正しく認定 / 実際の陽性 )\n",
        "(実際の陽性の中で正しく認定されたもの)\n",
        "\n",
        "* F1スコアは、適合率と再現率の調和平均で定義されます。一般に、適合率と再現率はトレードオフの関係にあるため、F1スコアはこれらのバランスを評価するための指標とみることができます。  \n",
        "検索結果に含まれる文書が多くなれば再現率は当然上がりますが，その分不必要な文書も増える可能性があるので，適合率は下がる傾向にあります．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX-f4arThStO"
      },
      "source": [
        "(N = 分類するクラス数, ni = そのクラスに分類された総数,xi = そのクラスに分類されたうち実際に正解だった数...と捉えると分かりやすい？)\n",
        "\n",
        "マイクロ平均とは\n",
        "**全クラスいっせい**(各クラスのTP, FP, FNをまとめる)に、平均したもの  \n",
        "正解率の場合：Nセットのテストをする。iセット目のテストはni回のテストで構成されるとする。𝑛𝑖回のテストのうち，𝑥𝑖回が正解の場合，マイクロ平均は次式：\n",
        "$\\frac{\\sum_{i=1}^{N} x_i}{\\sum_{i=1}^{N} n_i}$  \n",
        "\n",
        "マクロ平均とは\n",
        "**クラスごと**にF1値を計算し(各クラスでTP, FP, FNを求める)にF1値を計算したもの  \n",
        "正解率の場合：𝑛𝑖回のテストのうち，𝑥𝑖回が正解の場合，マクロ平均は次式：\n",
        "$\\frac{1}{N}\\sum_{i=1}^{N}\\frac{x_i}{n_i}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eULZvd5szvS_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "6031f6cb-c069-454d-c5b4-d336a4c53e1f"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "# 適合率\n",
        "precision_each = list(precision_score(test['CATEGORY'], test_pred[0], average=None, labels=['b', 'e', 't', 'm'])) # average = Noneを指定するとクラスごとの精度をndarrayで返す。   \n",
        "precision_micro = [precision_score(test['CATEGORY'],test_pred[0], average='micro')]  # マイクロ平均(全体の精度)\n",
        "precision_macro = [precision_score(test['CATEGORY'],test_pred[0], average='macro')]  # マクロ平均(クラスごとの精度の平均)\n",
        "\n",
        "precision = precision_each + precision_micro + precision_macro\n",
        "\n",
        "# 再現率\n",
        "recall_each = list(recall_score(test['CATEGORY'], test_pred[0], average=None, labels=['b', 'e', 't', 'm']))\n",
        "recall_micro = [recall_score(test['CATEGORY'], test_pred[0], average='micro')]\n",
        "recall_macro = [recall_score(test['CATEGORY'], test_pred[0], average='macro')]\n",
        "\n",
        "recall = recall_each + recall_micro + recall_macro\n",
        "\n",
        "# F1スコア\n",
        "f1_each = list(f1_score(test['CATEGORY'], test_pred[0], average=None, labels=['b', 'e', 't', 'm']))\n",
        "f1_micro = [f1_score(test['CATEGORY'], test_pred[0], average='micro')]\n",
        "f1_macro = [f1_score(test['CATEGORY'], test_pred[0], average='macro')]\n",
        "\n",
        "f1 = f1_each + f1_micro + f1_macro\n",
        "\n",
        "scores = pd.DataFrame({'適合率': precision, '再現率': recall, 'F1スコア': f1},  # 列名\n",
        "                      index=['b', 'e', 't', 'm', 'マイクロ平均', 'マクロ平均'])  # 行名\n",
        "# 例えば、precisionの１列目は、b, e, t, mの適合率、そのマイクロ平均、そのマクロ平均が縦に並ぶ\n",
        "\n",
        "display(scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>適合率</th>\n",
              "      <th>再現率</th>\n",
              "      <th>F1スコア</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>b</th>\n",
              "      <td>0.907376</td>\n",
              "      <td>0.939609</td>\n",
              "      <td>0.923211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>e</th>\n",
              "      <td>0.862944</td>\n",
              "      <td>0.965909</td>\n",
              "      <td>0.911528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>t</th>\n",
              "      <td>0.862069</td>\n",
              "      <td>0.657895</td>\n",
              "      <td>0.746269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>m</th>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.439560</td>\n",
              "      <td>0.592593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>マイクロ平均</th>\n",
              "      <td>0.883808</td>\n",
              "      <td>0.883808</td>\n",
              "      <td>0.883808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>マクロ平均</th>\n",
              "      <td>0.885370</td>\n",
              "      <td>0.750743</td>\n",
              "      <td>0.793400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             適合率       再現率     F1スコア\n",
              "b       0.907376  0.939609  0.923211\n",
              "e       0.862944  0.965909  0.911528\n",
              "t       0.862069  0.657895  0.746269\n",
              "m       0.909091  0.439560  0.592593\n",
              "マイクロ平均  0.883808  0.883808  0.883808\n",
              "マクロ平均   0.885370  0.750743  0.793400"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiU08ynGs27m"
      },
      "source": [
        "## 57. 特徴量の重みの確認\n",
        "\n",
        "52で学習したロジスティック回帰モデルの中で，重みの高い特徴量トップ10と，重みの低い特徴量トップ10を確認せよ．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qepwptkUkeS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5917920-54f4-4373-e700-176b939c476f"
      },
      "source": [
        "# X_train : tf-idfを算出したもの(行：文書番号  列：各語彙のtf-idf値)(DataFrame型)\n",
        "for class_, weight in zip(model.classes_, model.coef_):  # classes_:クラス名のリスト  # coef_: 学習した各特徴量の重みは、クラスごとに(１つのリストで?)coef_に格納\n",
        "  print(class_)\n",
        "  best10 = pd.DataFrame(X_train.columns.values[np.argsort(weight)[::-1][:10]], columns=['上位10位'], index=range(1, 11)).T\n",
        "    # .columnsで列名取得。インデックスオブジェクトではなくリストにしたい場合は.columns.values\n",
        "  # np.argsort()は値ではなく並び替えたインデックス（元のndarrayでの位置 = 0始まりの順番）のndarrayを返す。\n",
        "    # np.sort()関数にはPython標準のsort()メソッドやsorted()関数のように引数reverseは存在しない。降順(大きい順)にしたい場合はスライス[::-1]を使う。\n",
        "\n",
        "  worst10 = pd.DataFrame(X_train.columns.values[np.argsort(weight)[:10]], columns=['下位10位'], index=range(1, 11)).T\n",
        "  display(pd.concat([best10, worst10], axis=0))\n",
        "  print('\\n')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>上位10位</th>\n",
              "      <td>bank</td>\n",
              "      <td>fed</td>\n",
              "      <td>stocks</td>\n",
              "      <td>china</td>\n",
              "      <td>ecb</td>\n",
              "      <td>ukraine</td>\n",
              "      <td>obamacare</td>\n",
              "      <td>euro</td>\n",
              "      <td>oil</td>\n",
              "      <td>yellen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>下位10位</th>\n",
              "      <td>her</td>\n",
              "      <td>ebola</td>\n",
              "      <td>video</td>\n",
              "      <td>she</td>\n",
              "      <td>the</td>\n",
              "      <td>aereo</td>\n",
              "      <td>and</td>\n",
              "      <td>virus</td>\n",
              "      <td>microsoft</td>\n",
              "      <td>google</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         1      2       3      4   ...         7      8          9       10\n",
              "上位10位  bank    fed  stocks  china  ...  obamacare   euro        oil  yellen\n",
              "下位10位   her  ebola   video    she  ...        and  virus  microsoft  google\n",
              "\n",
              "[2 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "e\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>上位10位</th>\n",
              "      <td>kardashian</td>\n",
              "      <td>chris</td>\n",
              "      <td>star</td>\n",
              "      <td>miley</td>\n",
              "      <td>she</td>\n",
              "      <td>movie</td>\n",
              "      <td>thrones</td>\n",
              "      <td>paul</td>\n",
              "      <td>he</td>\n",
              "      <td>kim</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>下位10位</th>\n",
              "      <td>us</td>\n",
              "      <td>google</td>\n",
              "      <td>update</td>\n",
              "      <td>study</td>\n",
              "      <td>gm</td>\n",
              "      <td>china</td>\n",
              "      <td>facebook</td>\n",
              "      <td>billion</td>\n",
              "      <td>ceo</td>\n",
              "      <td>could</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               1       2       3      4   ...        7        8    9      10\n",
              "上位10位  kardashian   chris    star  miley  ...   thrones     paul   he    kim\n",
              "下位10位          us  google  update  study  ...  facebook  billion  ceo  could\n",
              "\n",
              "[2 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>上位10位</th>\n",
              "      <td>ebola</td>\n",
              "      <td>study</td>\n",
              "      <td>fda</td>\n",
              "      <td>drug</td>\n",
              "      <td>cancer</td>\n",
              "      <td>mers</td>\n",
              "      <td>cases</td>\n",
              "      <td>could</td>\n",
              "      <td>cigarettes</td>\n",
              "      <td>health</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>下位10位</th>\n",
              "      <td>facebook</td>\n",
              "      <td>gm</td>\n",
              "      <td>bank</td>\n",
              "      <td>apple</td>\n",
              "      <td>ceo</td>\n",
              "      <td>google</td>\n",
              "      <td>game</td>\n",
              "      <td>climate</td>\n",
              "      <td>twitter</td>\n",
              "      <td>deal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             1      2     3      4   ...     7        8           9       10\n",
              "上位10位     ebola  study   fda   drug  ...  cases    could  cigarettes  health\n",
              "下位10位  facebook     gm  bank  apple  ...   game  climate     twitter    deal\n",
              "\n",
              "[2 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "t\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>上位10位</th>\n",
              "      <td>google</td>\n",
              "      <td>facebook</td>\n",
              "      <td>apple</td>\n",
              "      <td>microsoft</td>\n",
              "      <td>climate</td>\n",
              "      <td>gm</td>\n",
              "      <td>tesla</td>\n",
              "      <td>nasa</td>\n",
              "      <td>earth</td>\n",
              "      <td>heartbleed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>下位10位</th>\n",
              "      <td>stocks</td>\n",
              "      <td>fed</td>\n",
              "      <td>her</td>\n",
              "      <td>percent</td>\n",
              "      <td>american</td>\n",
              "      <td>drug</td>\n",
              "      <td>shares</td>\n",
              "      <td>cancer</td>\n",
              "      <td>ukraine</td>\n",
              "      <td>still</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           1         2      3          4   ...      7       8        9           10\n",
              "上位10位  google  facebook  apple  microsoft  ...   tesla    nasa    earth  heartbleed\n",
              "下位10位  stocks       fed    her    percent  ...  shares  cancer  ukraine       still\n",
              "\n",
              "[2 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDGkKQupt5TM"
      },
      "source": [
        "##58. 正則化パラメータの変更\n",
        "\n",
        ">ロジスティック回帰モデルを学習するとき，正則化パラメータを調整することで，学習時の過学習（overfitting）の度合いを制御できる．異なる正則化パラメータでロジスティック回帰モデルを学習し，学習データ，検証データ，および評価データ上の正解率を求めよ．実験の結果は，正則化パラメータを横軸，正解率を縦軸としたグラフにまとめよ．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo0nl0Ext5BK"
      },
      "source": [
        "正則化 (Regularization)とは、過学習を防いで汎化性能（未知のデータへの対応能力）を高めるためのテクニックの一つで、モデルに「正則化項」というものを付けることでモデルの形が複雑になりすぎないように調整しようとするもの。パラメーターの値を十分小さくしてしまえば、説明変数がどんな多項式であっても、その説明変数の予測値への影響を小さくできるからオーバーフィットしにくくなる、という考えです。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "illDniCV3y0p"
      },
      "source": [
        "L1の正則化は、wの数値の多くが0になるようにし、次元圧縮を行います。\n",
        "L2の正則化は、wの数値をできるだけ0に近づけていこうという方向性でモデルの複雑化を防ごうとします。\n",
        "\n",
        "scikit-learnのロジスティック回帰には、デフォルトでL2という正則化が行われています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD7pRrjDldBf"
      },
      "source": [
        "result = []\n",
        "# 10^-5～10^4まで作成\n",
        "for C in np.logspace(-5, 4, 10, base=10):  # numpy.logspaceで対数スケールの配列を生成できます。\n",
        "                                                 # numpy.logspace(start, stop, num=50, base=10.0)\n",
        "                                                 #             (最初の値, 最後の値, 生成する配列の要素数, 底)\n",
        "  # モデルの学習\n",
        "  model = LogisticRegression(random_state=123, max_iter=10000, C=C)\n",
        "    # Cは正則化の強さを指定するパラメータ。正の値を指定する（デフォルト値は1.0）。Cの値が小さいほど正則化の強さが増す。\n",
        "    # Cを変えて学習結果を比較\n",
        "  model.fit(X_train, train['CATEGORY'])\n",
        "\n",
        "  # 予測値の取得\n",
        "  train_pred = model.predict(X_train)\n",
        "  valid_pred = model.predict(X_valid)\n",
        "  test_pred = model.predict(X_test)\n",
        "\n",
        "  # 正解率の算出\n",
        "  train_acc = accuracy_score(train['CATEGORY'], train_pred )\n",
        "  valid_acc = accuracy_score(valid['CATEGORY'], valid_pred )\n",
        "  test_acc = accuracy_score(test['CATEGORY'], test_pred )\n",
        "\n",
        "  # 結果の格納\n",
        "  result.append([C, train_acc, valid_acc, test_acc])  # リストの要素にリストを格納することで二次元配列構造を実現できる。\n",
        "                                                                     # リスト自体は次元の概念が無い？"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od6DLhH0lfgD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "ba48d0a2-3e70-4848-b0eb-d3029df8e530"
      },
      "source": [
        "# 視覚化\n",
        "result = np.array(result).T  # でもリストinリストしたものを転置させると、行列の転置と同じ挙動をする\n",
        "                             # これにより、Cだけでまとまったリスト・train_accuracyだけでまとまったリスト...が作れる！\n",
        "plt.plot(result[0], result[1], label='train')\n",
        "plt.plot(result[0], result[2], label='valid')\n",
        "plt.plot(result[0], result[3], label='test')\n",
        "plt.ylim(0, 1.1)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xscale ('log')\n",
        "plt.xlabel('C')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g63_5eGbIOFe"
      },
      "source": [
        "##59. ハイパーパラメータの探索\n",
        "\n",
        "学習アルゴリズムや学習パラメータを変えながら，カテゴリ分類モデルを学習せよ．検証データ上の正解率が最も高くなる学習アルゴリズム・パラメータを求めよ．また，その学習アルゴリズム・パラメータを用いたときの評価データ上の正解率を求めよ．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrGBFQ59QBPy"
      },
      "source": [
        "# Optuna(オプチュナ)はハイパーパラメータの最適化を自動化するためのソフトウェアフレームワーク\n",
        "!pip install optuna"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0RQVOepXOjD"
      },
      "source": [
        "　ハイパーパラメータとは、機械学習アルゴリズムの挙動を制御するパラメータのことです。特に深層学習では勾配法によって最適化できない・しないパラメータに相当します。例えば、学習率やバッチサイズ、学習イテレーション数といったようなものがハイパーパラメータとなります。また、ニューラルネットワークの層数やチャンネル数といったようなものもハイパーパラメータです。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3CccOJOUqUa"
      },
      "source": [
        "import optuna\n",
        "\n",
        "# 最適化対象を関数で指定\n",
        "def objective(trial): # trialは後々使われるOptunaに実装されているクラスのインスタンスです。適当な範囲から値をサンプリングしてくる役割\n",
        "  # チューニング対象パラメータのセット\n",
        "  # 今回は l1_ratio と C の値を変える\n",
        "  l1_ratio = trial.suggest_uniform('l1_ratio', 0, 1)  # l1_ratioという変数名で、[0, 1]の範囲の一様分布から値を取る\n",
        "  C = trial.suggest_loguniform('C', 1e-4, 1e4)  # 対数(log)領域で値を取る\n",
        "\n",
        "  # モデルの学習\n",
        "  # Elastic Netは一般化線形モデルの回帰に正則化項を加味するモデル。メリットとして次元削除と過学習防止を良い塩梅にやってくれるらしい。\n",
        "  model = LogisticRegression(random_state=123, \n",
        "                          max_iter=10000, \n",
        "                          penalty='elasticnet',   # 正則化の方法。L1, L2両方使う\n",
        "                          solver='saga',   # 最適化の方法. For multiclass problems\n",
        "                          l1_ratio=l1_ratio,  # L1正則化とL2正則化のバランスを指定\n",
        "                          C=C)\n",
        "  model.fit(X_train, train['CATEGORY'])\n",
        "\n",
        "  # 予測値の取得\n",
        "  valid_pred = model.predict(X_valid)\n",
        "\n",
        "  # 正解率の算出\n",
        "  valid_accuracy = accuracy_score(valid['CATEGORY'], valid_pred)    \n",
        "\n",
        "  return valid_accuracy "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2SCVThvYCMK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5355a623-c519-41c7-c291-4ca80a040489"
      },
      "source": [
        "# 最適化\n",
        "# 最適化を開始するには、Studyを作成し、目的関数をoptimize()に渡します。n_trialsは試行回数です。\n",
        "# たった上記のコードだけで「目的関数に値をランダムに入れてみて、最大値を見つける」というプログラムの完成です。\n",
        "# studyオブジェクトには最適化の結果が内部変数として保持されています。\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, timeout=3600)\n",
        "\n",
        "# 結果の表示\n",
        "print('Best trial:')\n",
        "trial = study.best_trial # study.best_valueは今回の実験で得られた目的関数の最大値\n",
        "print('  Value: {:.3f}'.format(trial.value))\n",
        "print('  Params: ')\n",
        "for key, value in trial.params.items():  # study.best_paramsはその時のハイパーパラメータの値。仮に多変数関数の最小・最大化を行った場合には、幾つかの変数を同時に扱うことになるので、study_paramsは各変数の名前と値を辞書で持ってくれています。便利ですね。\n",
        "  print('    {}: {}'.format(key, value))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-06-04 08:15:34,245]\u001b[0m A new study created in memory with name: no-name-4dd3184b-b379-49e1-b965-2d4f8c286b55\u001b[0m\n",
            "\u001b[32m[I 2021-06-04 08:15:35,144]\u001b[0m Trial 0 finished with value: 0.42128935532233885 and parameters: {'l1_ratio': 0.98972555975793, 'C': 0.0002912832225830733}. Best is trial 0 with value: 0.42128935532233885.\u001b[0m\n",
            "\u001b[32m[I 2021-06-04 08:15:39,278]\u001b[0m Trial 1 finished with value: 0.42128935532233885 and parameters: {'l1_ratio': 0.5307153488109865, 'C': 0.0016681367798321832}. Best is trial 0 with value: 0.42128935532233885.\u001b[0m\n",
            "\u001b[32m[I 2021-06-04 08:28:16,701]\u001b[0m Trial 2 finished with value: 0.8545727136431784 and parameters: {'l1_ratio': 0.6800830548968886, 'C': 146.11830790276045}. Best is trial 2 with value: 0.8545727136431784.\u001b[0m\n",
            "\u001b[32m[I 2021-06-04 08:45:50,704]\u001b[0m Trial 3 finished with value: 0.8508245877061469 and parameters: {'l1_ratio': 0.4870964547522324, 'C': 549.1174534666801}. Best is trial 2 with value: 0.8545727136431784.\u001b[0m\n",
            "\u001b[32m[I 2021-06-04 08:45:56,394]\u001b[0m Trial 4 finished with value: 0.42128935532233885 and parameters: {'l1_ratio': 0.22899418621141365, 'C': 0.0013885910248333016}. Best is trial 2 with value: 0.8545727136431784.\u001b[0m\n",
            "\u001b[32m[I 2021-06-04 08:46:14,900]\u001b[0m Trial 5 finished with value: 0.4197901049475262 and parameters: {'l1_ratio': 0.40791935726034734, 'C': 0.005837533428088537}. Best is trial 2 with value: 0.8545727136431784.\u001b[0m\n",
            "\u001b[32m[I 2021-06-04 08:46:17,420]\u001b[0m Trial 6 finished with value: 0.39580209895052476 and parameters: {'l1_ratio': 0.9268235989671642, 'C': 0.0006153695645518137}. Best is trial 2 with value: 0.8545727136431784.\u001b[0m\n",
            "\u001b[32m[I 2021-06-04 08:48:51,058]\u001b[0m Trial 7 finished with value: 0.8770614692653673 and parameters: {'l1_ratio': 0.0642747488127583, 'C': 38.071530393006654}. Best is trial 7 with value: 0.8770614692653673.\u001b[0m\n",
            "\u001b[32m[I 2021-06-04 08:49:15,895]\u001b[0m Trial 8 finished with value: 0.868815592203898 and parameters: {'l1_ratio': 0.4622296859448982, 'C': 0.663605436214287}. Best is trial 7 with value: 0.8770614692653673.\u001b[0m\n",
            "\u001b[32m[I 2021-06-04 08:56:07,379]\u001b[0m Trial 9 finished with value: 0.8605697151424287 and parameters: {'l1_ratio': 0.3034947959961394, 'C': 117.04821996853985}. Best is trial 7 with value: 0.8770614692653673.\u001b[0m\n",
            "\u001b[32m[I 2021-06-04 09:26:01,433]\u001b[0m Trial 10 finished with value: 0.8478260869565217 and parameters: {'l1_ratio': 0.015724705020149832, 'C': 8691.90422094874}. Best is trial 7 with value: 0.8770614692653673.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best trial:\n",
            "  Value: 0.877\n",
            "  Params: \n",
            "    l1_ratio: 0.0642747488127583\n",
            "    C: 38.071530393006654\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}